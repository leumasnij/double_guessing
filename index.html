<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Website for ICRA 25 Paper Learning to Double Guess">
  <meta property="og:title" content="Learning to Double Guess: An Active Perception Approach for Estimating the Center of Mass of Arbitrary Object"/>
  <meta property="og:description" content="Cooking robots have long been desired by the commercial market, while the technical challenge is significant. A major difficulty comes from the demand of perceiving and handling liquid with different properties. This paper presents a robot system that mixes batter and makes pancakes out of it, where understanding and handling the viscous liquid is an essential component. The system integrates advanced sensory and control algorithms to autonomously stir flour and water to achieve the desired batter uniformity, estimate the batter’s properties such as the water-flour ratio and liquid level, as well as perform precise manipulations to pour the batter into any specified shape. Experimental results show the system’s capability to always produce batter of desired uniformity, estimate water-flour ratio and liquid level precisely and accurately pour it into complex shapes. This research marks a significant stride towards automating culinary pro- cesses, showcasing the potential for robots to assist in domestic kitchens and revolutionize the process of food preparation."/>
  <meta property="og:url" content="https://luoxinyuan.github.io/pancake/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/teaser3.png"/>
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="Learning to Double Guess: An Active Perception Approach for Estimating the Center of Mass of Arbitrary Object">
  <meta name="twitter:description" content="Cooking robots have long been desired by the commercial market, while the technical challenge is significant. A major difficulty comes from the demand of perceiving and handling liquid with different properties. This paper presents a robot system that mixes batter and makes pancakes out of it, where understanding and handling the viscous liquid is an essential component. The system integrates advanced sensory and control algorithms to autonomously stir flour and water to achieve the desired batter uniformity, estimate the batter’s properties such as the water-flour ratio and liquid level, as well as perform precise manipulations to pour the batter into any specified shape. Experimental results show the system’s capability to always produce batter of desired uniformity, estimate water-flour ratio and liquid level precisely and accurately pour it into complex shapes. This research marks a significant stride towards automating culinary pro- cesses, showcasing the potential for robots to assist in domestic kitchens and revolutionize the process of food preparation."/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/teaser3.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Double Guess">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Learning to Double Guess: An Active Perception Approach for Estimating the Center of Mass of Arbitrary Object</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Learning to Double Guess:</h1>
            <h2 class="title is-2"> An Active Perception Approach for Estimating the Center of Mass of Arbitrary Object</h2>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                  <a href="https://leumasnij.github.io" target="_blank">Shengmiao Jin</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="" target="_blank">Yuchen Mo</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="https://cs.illinois.edu/about/people/all-faculty/yuanwz" target="_blank">Wenzhen Yuan</a><sup>1</sup></span>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>University of Illinois Urbana-Champaign<br>
                      IEEE international Conference on Robotics and Automation (ICRA), 2025</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="http://www.arxiv.org/abs/2407.01755" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary -->
                    <span class="link-block">
                      <a href="https://github.com/leumasnij/double_guessing" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Codebase</span>
                    </a>
                  </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/Website Teaser.png" />
    </div>
  </div>
</section>
<!--End teaser image -->


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Manipulating arbitrary objects in unstructured environments is a significant challenge in robotics, primarily due to difficulties in determining an object's center of mass. This paper introduces U-GRAPH: Uncertainty-Guided Rotational Active Perception with Haptics, a novel framework to enhance the center of mass estimation using active perception. Traditional methods often rely on single interaction and are limited by the inherent inaccuracies of Force-Torque (F/T) sensors. Our approach circumvents these limitations by integrating a Bayesian Neural Network (BNN) to quantify uncertainty and guide the robotic system through multiple, information-rich interactions via grid search and a neural network that scores each action. We demonstrate the remarkable generalizability and transferability of our method with training on a small dataset with limited variation yet still perform well on unseen complex real-world objects.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-4">Video Introduction </h2>
      <div class="item item-video1">
          <video poster="" id="video1" controls muted loop height="100%">
            <source src="static/videos/icra25.mp4"
            type="video/mp4">
          </video>
      </div>
    </div>
  </div>
</section>

<!-- method-->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Method</h2>
      <h2 class="title is-4">Intuitive Physcial Model for Center of Mass</h2>
      <div class="content has-text-justified">
        <p>
          After grasping the object, we define its CoM by some displacement dx, dy, and dz away from the grasping point. 
        </p>
        <h2 class="title is-4">Data Collection Setup</h2>
      <div class="content has-text-justified">
        <p>
          The hardware system features a 6-DoF UR5e robot arm. Attached to the robot's wrist is a 6-axis NRS-6050-D80 F/T sensor from Nordbo Robotics with a sampling rate of 1000 Hz. The arm is also equipped with a WSG-50 2-fingered gripper from Weiss Robotics with customized PLA 3D-printed fingers. For data collection, we designed and 3D-printed two objects with dimensions of 15cm * 15cm * 8cm, each including two holders sized 4cm * 4cm for placing AprilTags. The plate object weighs 127.36 grams and allows grasp onto the center. The box object weighs 185.36 grams and is designated to be grasped on the side. We utilize standard laboratory weights for the experiments, specifically two 100-gram weights and one 200-gram weight.
        </p>
      </div>
      <img src="static/images/setup.png" alt="img 1" style="width: 40%; height: auto;" />
      <img src="static/images/modeling3.png" alt="img 2" style="width: 56%; height: auto;" />
      </div>
    </div>
  </div>
</section>



<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-4">Main Pipeline</h2>
      <div class="content has-text-justified">
        <p>
          Targeting a generalized and robust CoM estimation framework, we propose U-GRAPH: Uncertainty-Guided Rotational Active Perception with Haptics. This system incorporates a BNN that processes 6-dimensional force-torque readings and 2-dimensional orientation data to yield a 3-dimensional CoM estimation. U-GRAPH also features ActiveNet, which utilizes the output from the BNN to determine the next best action. Assuming the robot has already grasped the object, we perform two measurements at different orientations to accurately estimate its CoM. The BNN supplies both prior predictions and quantifies uncertainty through the standard deviation. The ActiveNet takes in prior estimation distribution and uses grid search to calculate a score for each action to determine the best one. Specifically, the action space is the 2-dimensional orientation of the grasping pose. We define the action executed as changing the pose. For inference, we first use the fixed orientation to generate a prior estimation of the CoM location. Then ActiveNet performs a grid search over the entire action space and calculates the score for each action with prior estimation as input. 
        </p>
      </div>
        <img src="static/images/active2.png" />
      </div>
    </div>
  </div>
</section>

  
<!-- End method -->


<!-- experiments-->

<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Experiments</h2>
      <h2 class="title is-4">Training Sets Estimation Results</h2>
      <div class="content has-text-justified">
        <p>
          In our first experiment, we use the same plate and box setup but vary the weight configurations. We test five different weight configurations across both objects: no weight, a single 100-gram weight, two 100-gram weights placed together, two 100-gram weights placed separately, and two separate weights that weigh 300 grams in total. For each configuration, we conducted five randomly selected grasps.  The data for this experiment is captured using the same overhead camera and AprilTags setup as training.
        </p>
      </div>
      <div style="text-align: center;">
        <img src="static/images/error_bar.png">
      </div>
    </div>
  </div>
</section>

<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-4">Precise Pouring Results</h2>
      <div class="content has-text-justified">
        <p>
          We also perform experiments on a set of 12 real-world objects that are commonly seen in daily life. We predefined the grasping point and found the ground truth CoM by balancing each axe with a gripper.
      </div>
      <div style="text-align: center;">
        <img src="static/images/Table.png">
      </div>
    </div>
  </div>
</section>


<!-- End experiments -->


<!-- PDF -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title">Paper</h2>

      <iframe  src="static/pdf/LDGAP.pdf" width="100%" height="950">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End PDF -->


<!--BibTex citation -->

<!--End BibTex citation -->


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>